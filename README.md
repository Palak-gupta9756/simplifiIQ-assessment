# ğŸ§  SimplifiIQ AI Research Intern Assessment

This repository contains all three parts of the SimplifiIQ AI Research Intern Assessment.  
Each part demonstrates a different stage of automation, AI integration, and data visualization.

---

## ğŸ“‚ Folder Structure

```
SimplifiIQ-assessment/
â”‚
â”œâ”€â”€ Part-A/                # Data Cleaning
â”‚   â”œâ”€â”€ task_logs.csv
â”‚   â”œâ”€â”€ clean_data.py
â”‚   â””â”€â”€ output_summary.csv
â”‚
â”œâ”€â”€ Part-B/                # Web Scraping + Gemini API Summarization
â”‚   â”œâ”€â”€ scrape_summarize.py
â”‚   â”œâ”€â”€ urls.txt
â”‚   â”œâ”€â”€ scraped_summary.csv
â”‚   â”œâ”€â”€ .env
â”‚   
â”‚
â”œâ”€â”€ part-c-frontend/       # React Visualization Dashboard
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ scraped_summary.csv
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ App.js
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â””â”€â”€ node_modules/
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ§© PART A â€” Data Cleaning (Python)

### ğŸ¯ Objective
Clean raw task log data (e.g., invalid timestamps, negative durations) and produce a summary.

### ğŸ§° Dependencies
Install once (in your terminal):
```bash
pip install pandas
```

### â–¶ï¸ How to Run
1. Place your CSV file (`task_logs.csv`) in the `Part-A` folder.  
2. Run the script:
   ```bash
   cd Part-A
   python3 clean_data.py
   ```
3. The cleaned and summarized output will be saved as:
   ```
   output_summary.csv
   ```

### ğŸ§  Assumptions
- The input CSV contains columns:  
  `user, task_type, start, duration_min`
- Invalid timestamps or negative durations are skipped.

---

## ğŸ¤– PART B â€” AI Summarization (Gemini API + Python)

### ğŸ¯ Objective
Scrape webpage content, summarize it using **Google Gemini API**, and export results to a CSV.

### ğŸ§° Dependencies
```bash
pip install requests beautifulsoup4 pandas python-dotenv
```

### âš™ï¸ Environment Setup
Create a `.env` file **inside `Part-B/`** .  
Add your Gemini API key:
```
GEMINI_API_KEY=your_actual_api_key_here
```

### â–¶ï¸ How to Run
1. Add URLs in `urls.txt` (one per line).  
2. Run:
   ```bash
   cd Part-B
   python3 scrape_summarize.py
   ```
3. Output file:  
   ```
   scraped_summary.csv
   ```

### ğŸ§  Assumptions
- A valid Gemini API key is available via Google AI Studio.  
- The script uses **Gemini 2.5 Flash** model .  
- Internet connection is required for both scraping and summarization.

### âš¡ Error Handling  
- Stores all summaries or error messages in the output CSV.

---

## ğŸŒ PART C â€” React Frontend Visualization

### ğŸ¯ Objective
Build a simple React dashboard to view and filter the summarized CSV data.

### ğŸ§° Dependencies
Make sure Node.js and npm are installed.  
Inside `part-c-frontend/`, install required packages:
```bash
cd part-c-frontend
npm install
npm install papaparse
```

### â–¶ï¸ How to Run
```bash
npm start
```
Then open your browser at:
ğŸ‘‰ http://localhost:3000

### ğŸ“Š Features
- Displays CSV data in a clean table format  
- Includes a search/filter box  
- Has a refresh button to reload CSV data  
- Loads `scraped_summary.csv` from `/public` folder

### ğŸ§  Assumptions
- The CSV (`scraped_summary.csv`) generated from Part B is copied to:
  ```
  part-c-frontend/public/
  ```

---

## ğŸ”’ Security Notes

- The `.env` file (containing the API key) **is not uploaded**.  
- Sensitive and rebuildable files are excluded using `.gitignore`:
  ```
  .env
  venv/
  node_modules/
  __pycache__/
  package-lock.json
  package.json
  ```

---

## âœ… Summary of Deliverables

| Part | Description | Output File |
|------|--------------|--------------|
| A | Data Cleaning & Validation | `output_summary.csv` |
| B | Web Scraping + Gemini Summarization | `scraped_summary.csv` |
| C | React Dashboard Visualization | Web UI (localhost:3000) |

---

## ğŸ’¬ Author
**Palak Gupta**  
AI Research Intern Candidate â€” SimplifiIQ (2025)
